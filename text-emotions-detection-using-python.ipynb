{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7022527,"sourceType":"datasetVersion","datasetId":4038266}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re \nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-22T01:30:39.840238Z","iopub.execute_input":"2023-11-22T01:30:39.840778Z","iopub.status.idle":"2023-11-22T01:30:41.670852Z","shell.execute_reply.started":"2023-11-22T01:30:39.840744Z","shell.execute_reply":"2023-11-22T01:30:41.669917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(file):\n    data = []\n    with open(file, 'r')as f:\n        for line in f:\n            line = line.strip()\n            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n            text = line[line.find(\"]\")+1:].strip()\n            data.append([label, text])\n    return data\n\nfile = '/kaggle/input/text-emotions/Text Emotions Detection.txt'\ndata = read_data(file)\nprint(\"Number of instances: {}\".format(len(data)))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T01:35:24.808609Z","iopub.execute_input":"2023-11-22T01:35:24.808996Z","iopub.status.idle":"2023-11-22T01:35:24.927348Z","shell.execute_reply.started":"2023-11-22T01:35:24.808968Z","shell.execute_reply":"2023-11-22T01:35:24.925826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ngram(token, n): \n    output = []\n    for i in range(n-1, len(token)): \n        ngram = ' '.join(token[i-n+1:i+1])\n        output.append(ngram) \n    return output\n\ndef create_feature(text, nrange=(1, 1)):\n    text_features = [] \n    text = text.lower() \n    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n    for n in range(nrange[0], nrange[1]+1): \n        text_features += ngram(text_alphanum.split(), n)    \n    text_punc = re.sub('[a-z0-9]', ' ', text)\n    text_features += ngram(text_punc.split(), 1)\n    return Counter(text_features)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T01:36:16.810271Z","iopub.execute_input":"2023-11-22T01:36:16.810636Z","iopub.status.idle":"2023-11-22T01:36:16.820306Z","shell.execute_reply.started":"2023-11-22T01:36:16.810607Z","shell.execute_reply":"2023-11-22T01:36:16.818984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_label(item, name): \n    items = list(map(float, item.split()))\n    label = \"\"\n    for idx in range(len(items)): \n        if items[idx] == 1: \n            label += name[idx] + \" \"\n    \n    return label.strip()\n\nemotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n\nX_all = []\ny_all = []\nfor label, text in data:\n    y_all.append(convert_label(label, emotions))\n    X_all.append(create_feature(text, nrange=(1, 4)))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T01:36:44.907585Z","iopub.execute_input":"2023-11-22T01:36:44.907981Z","iopub.status.idle":"2023-11-22T01:36:45.495097Z","shell.execute_reply.started":"2023-11-22T01:36:44.907951Z","shell.execute_reply":"2023-11-22T01:36:45.493539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)\n\ndef train_test(clf, X_train, X_test, y_train, y_test):\n    clf.fit(X_train, y_train)\n    train_acc = accuracy_score(y_train, clf.predict(X_train))\n    test_acc = accuracy_score(y_test, clf.predict(X_test))\n    return train_acc, test_acc\n\nfrom sklearn.feature_extraction import DictVectorizer\nvectorizer = DictVectorizer(sparse = True)\nX_train = vectorizer.fit_transform(X_train)\nX_test = vectorizer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T01:37:02.334914Z","iopub.execute_input":"2023-11-22T01:37:02.335302Z","iopub.status.idle":"2023-11-22T01:37:03.547581Z","shell.execute_reply.started":"2023-11-22T01:37:02.335273Z","shell.execute_reply":"2023-11-22T01:37:03.545746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc = SVC()\nlsvc = LinearSVC(random_state=123)\nrforest = RandomForestClassifier(random_state=123)\ndtree = DecisionTreeClassifier()\n\nclifs = [svc, lsvc, rforest, dtree]\n\n# train and test them \nprint(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\nprint(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\nfor clf in clifs: \n    clf_name = clf.__class__.__name__\n    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T01:37:20.650763Z","iopub.execute_input":"2023-11-22T01:37:20.651164Z","iopub.status.idle":"2023-11-22T01:39:22.535491Z","shell.execute_reply.started":"2023-11-22T01:37:20.651130Z","shell.execute_reply":"2023-11-22T01:39:22.534069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nl = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\nl.sort()\nlabel_freq = {}\nfor label, _ in data: \n    label_freq[label] = label_freq.get(label, 0) + 1\n\n# print the labels and their counts in sorted order \nfor l in sorted(label_freq, key=label_freq.get, reverse=True):\n    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T01:39:45.277986Z","iopub.execute_input":"2023-11-22T01:39:45.278372Z","iopub.status.idle":"2023-11-22T01:39:45.291260Z","shell.execute_reply.started":"2023-11-22T01:39:45.278339Z","shell.execute_reply":"2023-11-22T01:39:45.289596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nemoji_dict = {\"joy\":\"ðŸ˜‚\", \"fear\":\"ðŸ˜±\", \"anger\":\"ðŸ˜ \", \"sadness\":\"ðŸ˜¢\", \"disgust\":\"ðŸ˜’\", \"shame\":\"ðŸ˜³\", \"guilt\":\"ðŸ˜³\"}\nt1 = \"This looks so impressive\"\nt2 = \"I have a fear of dogs\"\nt3 = \"My dog died yesterday\"\nt4 = \"I don't love you anymore..!\"\n\ntexts = [t1, t2, t3, t4]\nfor text in texts: \n    features = create_feature(text, nrange=(1, 4))\n    features = vectorizer.transform(features)\n    prediction = clf.predict(features)[0]\n    print( text,emoji_dict[prediction])","metadata":{"execution":{"iopub.status.busy":"2023-11-22T01:40:03.076448Z","iopub.execute_input":"2023-11-22T01:40:03.076813Z","iopub.status.idle":"2023-11-22T01:40:03.086749Z","shell.execute_reply.started":"2023-11-22T01:40:03.076783Z","shell.execute_reply":"2023-11-22T01:40:03.085782Z"},"trusted":true},"execution_count":null,"outputs":[]}]}